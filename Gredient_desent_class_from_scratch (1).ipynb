{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iLA7qskMSNzg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"test.csv\")"
      ],
      "metadata": {
        "id": "sgarYdzGUDYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.iloc[:,:-1].values\n",
        "y=df.iloc[:,-1].values"
      ],
      "metadata": {
        "id": "1ROzPTj8T8Cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train ,X_test ,y_train ,y_test=train_test_split(X ,y,test_size=0.2 , random_state=0)"
      ],
      "metadata": {
        "id": "nSKNMQvuTvda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### code for the gradient desent"
      ],
      "metadata": {
        "id": "Dh6__HXjXAw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GDRegressor:\n",
        "\n",
        "    def __init__(self,learning_rate,epochs):\n",
        "        self.m = 100\n",
        "        self.b = -120\n",
        "        self.lr = learning_rate\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def fit(self,X,y):\n",
        "        # calcualte the b using GD\n",
        "        for i in range(self.epochs):\n",
        "            loss_slope_b = -2 * np.sum(y - self.m*X.ravel() - self.b)\n",
        "            loss_slope_m = -2 * np.sum((y - self.m*X.ravel() - self.b)*X.ravel())\n",
        "\n",
        "            self.b = self.b - (self.lr * loss_slope_b)\n",
        "            self.m = self.m - (self.lr * loss_slope_m)\n",
        "        print(self.m,self.b)\n",
        "\n",
        "    def predict(self,X):\n",
        "        return self.m * X + self.b\n",
        "\n",
        "\n",
        "SGD=GDRegressor(0.001 , 50)\n",
        "SGD.fit(X_train,y_train)\n",
        "\n",
        "y_pred = SGD.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score(y_test,y_pred)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BYx_lLDPSbbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batch-Gradint_desent"
      ],
      "metadata": {
        "id": "-iKe9sulVT5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GDRegressor:\n",
        "\n",
        "    def __init__(self,learning_rate=0.01,epochs=100):\n",
        "\n",
        "        self.coef_ = None\n",
        "        self.intercept_ = None\n",
        "        self.lr = learning_rate\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def fit(self,X_train,y_train):\n",
        "        # init your coefs\n",
        "\n",
        "        self.intercept_ = 0\n",
        "        self.coef_ = np.ones(X_train.shape[1])\n",
        "        for i in range(self.epochs):\n",
        "\n",
        "            # update all the coef and the intercept\n",
        "            y_hat = np.dot(X_train,self.coef_) + self.intercept_\n",
        "            #print(\"Shape of y_hat\",y_hat.shape)\n",
        "\n",
        "            intercept_der = -2 * np.mean(y_train - y_hat)\n",
        "            self.intercept_ = self.intercept_ - (self.lr * intercept_der)\n",
        "\n",
        "            coef_der = -2 * np.dot((y_train - y_hat),X_train)/X_train.shape[0]\n",
        "            self.coef_ = self.coef_ - (self.lr * coef_der)\n",
        "        print(self.intercept_,self.coef_)\n",
        "\n",
        "    def predict(self,X_test):\n",
        "        return np.dot(X_test,self.coef_) + self.intercept_\n"
      ],
      "metadata": {
        "id": "SurjBUZSVSmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### code for the stocastic gredient desent"
      ],
      "metadata": {
        "id": "ClOW3EfcXHmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SGDRegressor:\n",
        "\n",
        "    def __init__(self,learning_rate=0.01,epochs=100):\n",
        "\n",
        "        self.coef_ = None\n",
        "        self.intercept_ = None\n",
        "        self.lr = learning_rate\n",
        "        self.epochs = epochs\n",
        "\n",
        "\n",
        "    def fit(self,X_train,y_train):\n",
        "        # init your coefs\n",
        "        self.intercept_ = 0\n",
        "        self.coef_ = np.ones(X_train.shape[1])\n",
        "\n",
        "        for i in range(self.epochs):\n",
        "            for j in range(X_train.shape[0]):\n",
        "                idx = np.random.randint(0,X_train.shape[0])\n",
        "\n",
        "                y_hat = np.dot(X_train[idx],self.coef_) + self.intercept_\n",
        "\n",
        "                intercept_der = -2 * (y_train[idx] - y_hat)\n",
        "                self.intercept_ = self.intercept_ - (self.lr * intercept_der)\n",
        "\n",
        "                coef_der = -2 * np.dot((y_train[idx] - y_hat),X_train[idx])\n",
        "                self.coef_ = self.coef_ - (self.lr * coef_der)\n",
        "\n",
        "        print(self.intercept_,self.coef_)\n",
        "\n",
        "    def predict(self,X_test):\n",
        "        return np.dot(X_test,self.coef_) + self.intercept_\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "hlMuGxVcW_if"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#suppose u have to use the sgd regressor present in the scikit-learn\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "reg = SGDRegressor(max_iter=100,learning_rate='constant',eta0=0.01)\n",
        "reg.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "NqW7tYz3ZB00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### miniBatch gradient desent"
      ],
      "metadata": {
        "id": "ytShrsjXYwDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class MBGDRegressor:\n",
        "\n",
        "    def __init__(self,batch_size,learning_rate=0.01,epochs=100):\n",
        "\n",
        "        self.coef_ = None\n",
        "        self.intercept_ = None\n",
        "        self.lr = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def fit(self,X_train,y_train):\n",
        "        # init your coefs\n",
        "        self.intercept_ = 0\n",
        "        self.coef_ = np.ones(X_train.shape[1])\n",
        "\n",
        "        for i in range(self.epochs):\n",
        "\n",
        "            for j in range(int(X_train.shape[0]/self.batch_size)):\n",
        "\n",
        "                idx = random.sample(range(X_train.shape[0]),self.batch_size)\n",
        "\n",
        "                y_hat = np.dot(X_train[idx],self.coef_) + self.intercept_\n",
        "                #print(\"Shape of y_hat\",y_hat.shape)\n",
        "                intercept_der = -2 * np.mean(y_train[idx] - y_hat)\n",
        "                self.intercept_ = self.intercept_ - (self.lr * intercept_der)\n",
        "\n",
        "                coef_der = -2 * np.dot((y_train[idx] - y_hat),X_train[idx])\n",
        "                self.coef_ = self.coef_ - (self.lr * coef_der)\n",
        "\n",
        "        print(self.intercept_,self.coef_)\n",
        "\n",
        "    def predict(self,X_test):\n",
        "        return np.dot(X_test,self.coef_) + self.intercept_\n",
        "mbr = MBGDRegressor(batch_size=int(X_train.shape[0]/50),learning_rate=0.01,epochs=100)\n",
        "mbr.fit(X_train,y_train)\n"
      ],
      "metadata": {
        "id": "fTgVn4yEYvrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bini batch using the stocastic GD\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "sgd = SGDRegressor(learning_rate='constant',eta0=0.1)\n",
        "batch_size = 35\n",
        "\n",
        "for i in range(100):\n",
        "\n",
        "    idx = random.sample(range(X_train.shape[0]),batch_size)\n",
        "    sgd.partial_fit(X_train[idx],y_train[idx])\n",
        "sgd.coef_\n"
      ],
      "metadata": {
        "id": "Kij-OEaadVxK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}