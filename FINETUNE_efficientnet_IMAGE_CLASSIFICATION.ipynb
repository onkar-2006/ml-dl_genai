{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "y_XBdzEtwOx_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.applications import EfficientNetB6\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "wk-mCx5gwMcD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#When the model is intended for transfer learning, the Keras implementation provides a option to remove the top layers:\n",
        "\"\"\"This option excludes the final Dense layer that turns 1280 features on the penultimate\n",
        "layer into prediction of the 1000 ImageNet classes.\n",
        "Replacing the toplayer with custom layers allows using EfficientNet\n",
        "as a feature extractor in a transfer learning workflow\"\"\"\n",
        "\n",
        "model=EfficientNetB6(include_top=False , wwights='imagenet')"
      ],
      "metadata": {
        "id": "8RuY25qgw22L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"stanford_dogs\"\n",
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    dataset_name, split=[\"train\", \"test\"], with_info=True, as_supervised=True\n",
        ")\n",
        "NUM_CLASSES = ds_info.features[\"label\"].num_classes\n"
      ],
      "metadata": {
        "id": "sbWT4XNvuXzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_augmentation_layers = [\n",
        "    layers.RandomRotation(factor=0.15),\n",
        "    layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
        "    layers.RandomFlip(),\n",
        "    layers.RandomContrast(factor=0.1),\n",
        "]\n",
        "\n",
        "\n",
        "def img_augmentation(images):\n",
        "    for layer in img_augmentation_layers:\n",
        "        images = layer(images)\n",
        "    return images"
      ],
      "metadata": {
        "id": "Z24HkvIAzgdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE=256"
      ],
      "metadata": {
        "id": "AHg4CpAz0MFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size = (IMG_SIZE, IMG_SIZE)\n",
        "ds_train = ds_train.map(lambda image, label: (tf.image.resize(image, size), label))\n",
        "ds_test = ds_test.map(lambda image, label: (tf.image.resize(image, size), label))"
      ],
      "metadata": {
        "id": "9lghwnAhu7OT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_label(label):\n",
        "    string_label = label_info.int2str(label)\n",
        "    return string_label.split(\"-\")[1]\n",
        "\n",
        "\n",
        "label_info = ds_info.features[\"label\"]\n",
        "for i, (image, label) in enumerate(ds_train.take(9)):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(image.numpy().astype(\"uint8\"))\n",
        "    plt.title(\"{}\".format(format_label(label)))\n",
        "    plt.axis(\"off\")\n"
      ],
      "metadata": {
        "id": "lHT6ooNpvB5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image, label in ds_train.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        aug_img = img_augmentation(np.expand_dims(image.numpy(), axis=0))\n",
        "        aug_img = np.array(aug_img)\n",
        "        plt.imshow(aug_img[0].astype(\"uint8\"))\n",
        "        plt.title(\"{}\".format(format_label(label)))\n",
        "        plt.axis(\"off\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "su1H8VxTvxMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=32\n",
        "# One-hot / categorical encoding\n",
        "def input_preprocess_train(image, label):\n",
        "    image = img_augmentation(image)\n",
        "    label = tf.one_hot(label, NUM_CLASSES)\n",
        "    return image, label\n",
        "\n",
        "\n",
        "def input_preprocess_test(image, label):\n",
        "    label = tf.one_hot(label, NUM_CLASSES)\n",
        "    return image, label\n",
        "\n",
        "ds_train = ds_train.map(input_preprocess_train, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_train = ds_train.batch(batch_size=BATCH_SIZE, drop_remainder=True)\n",
        "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "ds_test = ds_test.map(input_preprocess_test, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_test = ds_test.batch(batch_size=BATCH_SIZE, drop_remainder=True)"
      ],
      "metadata": {
        "id": "jIBXEIFK1XAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = EfficientNetB0(\n",
        "    include_top=True,\n",
        "    weights=None,\n",
        "    classes=NUM_CLASSES,\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        ")\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "epochs = 42\n",
        "hist = model.fit(ds_train, epochs=epochs, validation_data=ds_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "t5OY_BQd3LRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#transfer learning\n",
        "def build_model(num_classes):\n",
        "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    model = EfficientNetB0(include_top=False, input_tensor=inputs, weights=\"imagenet\")\n",
        "\n",
        "    # Freeze the pretrained weights\n",
        "    model.trainable = False\n",
        "\n",
        "    # Rebuild top\n",
        "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    top_dropout_rate = 0.2\n",
        "    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n",
        "\n",
        "    # Compile\n",
        "    model = keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=1e-2)\n",
        "    model.compile(\n",
        "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = build_model(num_classes=NUM_CLASSES)\n",
        "\n",
        "epochs = 25\n",
        "hist = model.fit(ds_train, epochs=epochs, validation_data=ds_test)\n",
        "plot_hist(hist)\n"
      ],
      "metadata": {
        "id": "ert9JnxX3jBV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}