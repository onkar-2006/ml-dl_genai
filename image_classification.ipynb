{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn  as sns\n",
        "from tensorflow.keras import layers\n",
        "import keras\n",
        "from tensorflow.keras.layers import Rescaling, Resizing\n",
        "from tensorflow.keras.layers import RandomRotation ,RandomCrop,RandomFlip\n",
        "from tensorflow.keras.layers import Conv2D ,MaxPooling2D ,AveragePooling2D ,GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Flatten , Dropout ,BatchNormalization ,LayerNormalization\n",
        "from tensorflow.keras.optimizers import RMSprop ,Adagrad ,Adam\n",
        "from tensorflow.keras.activations import sigmoid ,selu ,relu,softmax,tanh\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n"
      ],
      "metadata": {
        "id": "M5LqIQTeJdJl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE=25\n",
        "#loading the dataset\n",
        "dataset= keras.utils.image_dataset_from_directory(\n",
        "    \"dataset\" ,\n",
        "    image_size=(IMAGE_SIZE ,IMAGE_SIZE),\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    color_mode='rgb',\n",
        "    bath_size=32,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "WoDd6Hl9K3k8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the classes and the image_size and shape\n",
        "class_names=dataset.n_classes\n",
        "n_classes=3\n",
        "print(dataset.shape)\n",
        "for image_batch , label_batch in dataset.take(1):\n",
        "  print(image_batch.numpy())\n",
        "  print(label_batch.shape)"
      ],
      "metadata": {
        "id": "Lpcnz9iuLoQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ploting the images\n",
        "plt.figure(figsize=(10,5))\n",
        "for image_batch , label_batch in dataset.take(1):\n",
        "  for i in range(20):\n",
        "    ax=plt.subplots(3,4,i+1)\n",
        "    plt.imshow(image_batch[i].numpy().as_type(\"unint8\"))\n",
        "    plt.title(class_names[label_batch[i]])\n",
        "    plt.axis('off')\n"
      ],
      "metadata": {
        "id": "nxvaMsZTM07J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#resizing and rescaling the images\n",
        "train_size=0.8\n",
        "test_size=0.1\n",
        "val_size=0.1"
      ],
      "metadata": {
        "id": "4wibd9bkOL1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size=len(dataset)*train_size\n",
        "test_size=len(dataset)*test_size\n",
        "val_size=len(dataset)*val_size"
      ],
      "metadata": {
        "id": "5oylfzgkPVWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds=dataset.take(78)\n",
        "len(train_ds)\n",
        "test_ds=dataset.skip(78)\n",
        "len(test_ds)\n",
        "val_ds=dataset.skip(78)\n",
        "len(test_ds)"
      ],
      "metadata": {
        "id": "cFLk5ftpOq-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#keep the images size and normalize the images\n",
        "from tensorflow.keras import layers ,models ,Sequential\n",
        "resize_and_reshape_img=Sequential([\n",
        "        Resizing(256 ,256),\n",
        "        Rescaling(1./255),\n",
        "])"
      ],
      "metadata": {
        "id": "UzzGmYijPUvy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data agumentation\n",
        "from tensorflow.keras.layers import RandomZoom ,RandomRotation ,RandomFlip\n",
        "\n",
        "data_agumentation=Sequential([\n",
        "    RandomCrop(2 ,2),\n",
        "    RandomRotation(0.2),\n",
        "    RandomFlip(\"horizontal_and_vertical\"),\n",
        "])"
      ],
      "metadata": {
        "id": "0QfSgWk8Qp2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "train_ds = train_ds.map(\n",
        "    lambda x, y: (data_agumentation(x, training=True), y)\n",
        ").prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "XlF3P8jXRuWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.models.Sequential()\n",
        "\n",
        "IMAGE_SIZE = 256\n",
        "BATCH_SIZE = 32\n",
        "CHANNELS = n_classes\n",
        "n_classes = 36\n",
        "model=models.Sequential([\n",
        "    layers.Conv2D(32 , kernel_size=(3,3) ,strides=(2,2) ,padding='same', activation='relu', kernel_initializer='he_normal' , input_shape=(IMAGE_SIZE,IMAGE_SIZE,CHANNELS)),\n",
        "    layers.MaxPooling2D(poolsize=(2,2) ,stride='valid'),\n",
        "    layers.Conv2D(64 , kernel_size=(3,3) ,strides=(2,2) ,padding='same', activation='relu',kernel_initializer='he_normal'),\n",
        "    layers.Dropout(0.2)\n",
        "    layers.Conv2D(128 , kernel_size=(3,3) ,strides=(2,2) ,padding='same',activation='relu', kernel_initializer='he_normal'),\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(128 , kernel_size=(3,3) ,strides=(2,2) ,padding='same', activation='relu',kernel_initializer='he_normal'),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    layers.Dropout((0.1))\n",
        "    layers.Conv2D(128 , kernel_size=(3,3) ,strides=(2,2) ,padding='same',activation='relu', kernel_initializer='he_normal'),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    layers.Flatten()\n",
        "    layers.Dense(64 , activation='relu'),\n",
        "    layers.Dense(n_classes , activation='softmax'),\n",
        "])"
      ],
      "metadata": {
        "id": "ZovWPEmQR7_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks=EarlyStopping(monitor='val_loss',\n",
        "                        min_delta=0,\n",
        "                        patience=0,\n",
        "                        verbose=0,\n",
        "                        mode='auto',\n",
        "                        baseline=None,\n",
        "                        restore_best_weights=True),"
      ],
      "metadata": {
        "id": "Hi8iUq6pWAVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(Adam(earning_rate=0.002, beta_1=0.8) ,SparseCategoricalCrossentropy() , metrics=['accuracy'])\n",
        "history=model.fit(train_ds ,batch_size=32 , epochs=100 , callbacks=callbacks ,verbose=1  ,validation_data=val_ds)"
      ],
      "metadata": {
        "id": "122mCOxaVbjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.history[\"val_loss\"]\n",
        "history.history[\"loss\"]\n",
        "history.history[\"accuracy\"]\n",
        "history.history[\"val_accuracy\"]"
      ],
      "metadata": {
        "id": "r6oYdWG3WyST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
        "axs[0,0]=plt.plot(history.history[\"val_loss\"])\n",
        "axs[0,0].set_title(\"val_loss_curve\")\n",
        "axs[0,0].set_xlabel(\"X_axis\")\n",
        "axs[0,0].set_ylabel(\"y_axis\")\n",
        "\n",
        "axs[0,1]=plt.plot(history.history[\"loss\"])\n",
        "axs[0,1].set_title(\"loss_curve\")\n",
        "axs[0,1].set_xlabel(\"X_axis\")\n",
        "axs[0,1].set_ylabel(\"y_axis\")\n",
        "\n",
        "axs[1,0]=plt.plot(history.history[\"accuracy\"])\n",
        "axs[1,0].set_title(\"loss_curve\")\n",
        "axs[1,0].set_xlabel(\"X_axis\")\n",
        "axs[1,0].set_ylabel(\"y_axis\")\n",
        "\n",
        "axs[1,1]=plt.plot(history.history[\"val_accuracy\"])\n",
        "axs[1,1].set_title(\"loss_curve\")\n",
        "axs[1,1].set_xlabel(\"X_axis\")\n",
        "axs[1,1].set_ylabel(\"y_axis\")"
      ],
      "metadata": {
        "id": "e_v2PltdXFGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for label_batch ,image_batch  in dataset.take(1):\n",
        "  first_image=image_batch[0].numpy().as_type(\"uint8\")\n",
        "  first_label=label_batch[0].numpy()\n",
        "  print(\"prediction\")\n",
        "  plt.imshow(first_image)\n",
        "  print(f\"the actual_label:{first_label}\")\n",
        "  batch_prediction=model.predict(image_batch)\n",
        "  print(f\"predicted_label:{class_names[np.agrmax(batch_prediction[0])]}\")"
      ],
      "metadata": {
        "id": "Sq3t2cIuY53g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model ,img):\n",
        "  img_array=tf.keras.preprocessing.img_to_array(images[i].numpy()),\n",
        "  img_array=tf.expand_dims(img_array ,0),\n",
        "  prediction=model.predict(img_array)\n",
        "  predict_class=class_names[np.argmax(prediction[0])]\n",
        "  confidense=round(100 *(np.argmax(prediction[0]) ,2))\n",
        "  return predict_class ,confidense\n",
        "\n"
      ],
      "metadata": {
        "id": "UFy4PMFhaRfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "for images ,labels in test_ds.take(1):\n",
        "  for i in range(10):\n",
        "    ax=plt.subplot(3,3,i+1)\n",
        "    plt.imshow(images[i].numpy().astype('unit8'))\n",
        "    predicted_class , confidense=predict(model , images[i].numpy())\n",
        "    actual_class=class_names[labels[i]]\n",
        "    plt.title(f\"actual:{actual_class},\\n Predicted:{predicted_class}.\\n Confidense:{confidense}\")\n",
        "    plt.axis('off')\n",
        ""
      ],
      "metadata": {
        "id": "QP6clQdrbxQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_version = 1\n",
        "model.save(f\"../models/{model_version}.keras\")  # or use .h5 if you prefer\n",
        "import os\n",
        "\n",
        "model_version = 1\n",
        "model_dir = \"../models\"\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "\n",
        "model.save(f\"{model_dir}/{model_version}.keras\")"
      ],
      "metadata": {
        "id": "NM3QbHv9dI2G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}